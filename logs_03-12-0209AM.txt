{
  "threshold": 5, 
  "text_style": "bow", 
  "rootpath": "../VisualSearch", 
  "collection": "msrvtt10ktrain", 
  "overwrite": 0
}
../VisualSearch/msrvtt10ktrain/TextData/vocabulary/bow/word_vocab_5.pkl exists.
skip
{
  "threshold": 5, 
  "text_style": "rnn", 
  "rootpath": "../VisualSearch", 
  "collection": "msrvtt10ktrain", 
  "overwrite": 0
}
../VisualSearch/msrvtt10ktrain/TextData/vocabulary/rnn/word_vocab_5.pkl exists.
skip
<type 'type'>
{
  "grad_clip": 2, 
  "word_dim": 500, 
  "text_mapping_layers": "0-2048", 
  "num_epochs": 50, 
  "dataset": "msrvtt", 
  "text_kernel_sizes": "2-3-4", 
  "measure": "exp", 
  "lr_decay_rate": 0.99, 
  "n_caption": 20, 
  "overwrite": 1, 
  "workers": 5, 
  "text_norm": true, 
  "neg_sampling": "default", 
  "log_step": 10, 
  "visual_norm": true, 
  "max_violation": true, 
  "visual_feature": "resnet-152-img1k-flatten0_outputos", 
  "trainCollection": "msrvtt10ktrain", 
  "learning_rate": 0.0001, 
  "batch_padding": 0, 
  "direction": "all", 
  "optimizer": "adam", 
  "resume": "", 
  "dropout": 0.2, 
  "visual_kernel_num": 512, 
  "rootpath": "../VisualSearch", 
  "batch_size": 120, 
  "cv_name": "cvpr_2019", 
  "text_kernel_num": 512, 
  "testCollection": "msrvtt10ktest", 
  "visual_mapping_layers": "0-2048", 
  "cost_style": "sum", 
  "text_rnn_size": 512, 
  "vocab": "word_vocab_5", 
  "loss_fun": "cont", 
  "visual_rnn_size": 1024, 
  "visual_kernel_sizes": "2-3-4-5", 
  "concate": "full", 
  "postfix": "runs_0", 
  "val_metric": "recall", 
  "valCollection": "msrvtt10kval", 
  "model": "dual_encoding", 
  "margin": 0.2
}
../VisualSearch/msrvtt10ktrain/cvpr_2019/msrvtt10kval/dual_encoding_concate_full_dp_0.2_measure_exp/vocab_word_vocab_5_word_dim_500_text_rnn_size_512_text_norm_True_kernel_sizes_2-3-4_num_512/visual_feature_resnet-152-img1k-flatten0_outputos_visual_rnn_size_1024_visual_norm_True_kernel_sizes_2-3-4-5_num_512/mapping_text_0-2048_img_0-2048/loss_func_cont_margin_0.2_direction_all_max_violation_True_cost_style_sum/optimizer_adam_lr_0.0001_decay_0.99_grad_clip_2.0_val_metric_recall/runs_0
../VisualSearch/msrvtt10ktrain/cvpr_2019/msrvtt10kval/dual_encoding_concate_full_dp_0.2_measure_exp/vocab_word_vocab_5_word_dim_500_text_rnn_size_512_text_norm_True_kernel_sizes_2-3-4_num_512/visual_feature_resnet-152-img1k-flatten0_outputos_visual_rnn_size_1024_visual_norm_True_kernel_sizes_2-3-4-5_num_512/mapping_text_0-2048_img_0-2048/loss_func_cont_margin_0.2_direction_all_max_violation_True_cost_style_sum/optimizer_adam_lr_0.0001_decay_0.99_grad_clip_2.0_val_metric_recall/runs_0/model_best.pth.tar exists.
overwrite
../VisualSearch/msrvtt10ktrain/cvpr_2019/msrvtt10kval/dual_encoding_concate_full_dp_0.2_measure_exp/vocab_word_vocab_5_word_dim_500_text_rnn_size_512_text_norm_True_kernel_sizes_2-3-4_num_512/visual_feature_resnet-152-img1k-flatten0_outputos_visual_rnn_size_1024_visual_norm_True_kernel_sizes_2-3-4-5_num_512/mapping_text_0-2048_img_0-2048/loss_func_cont_margin_0.2_direction_all_max_violation_True_cost_style_sum/optimizer_adam_lr_0.0001_decay_0.99_grad_clip_2.0_val_metric_recall/runs_0/val_metric.txt exists.
overwrite
[BigFile] 305462x2048 instances loaded from ../VisualSearch/msrvtt10ktrain/FeatureData/resnet-152-img1k-flatten0_outputos
[BigFile] 305462x2048 instances loaded from ../VisualSearch/msrvtt10kval/FeatureData/resnet-152-img1k-flatten0_outputos
[BigFile] 1743364x500 instances loaded from ../VisualSearch/word2vec/flickr/vec500flickr30m
('getting pre-trained parameter for word embedding initialization', (7811, 500))
=======================Data Loaded=================================
>>>>>>>>>>>>>>>>>>>>
Contrastive Loss Used
Epoch[0 / 50] LR: 0.0001
----------
('=====================================', 120, '============================================')

   120/130260 [..............................] - ETA: 48:21 - loss: 3998.0259 * Text to video:
 * r_1_5_10: [0.231, 1.147, 2.143]
 * medr, meanr: [252.0, 248.664]
 * ----------
 * Video to text:
 * r_1_5_10: [0.201, 0.604, 1.006]
 * medr, meanr: [470.0, 741.521]
 * ----------
 * Current perf: 5.33199195171
 * Best perf: 5.33199195171

Epoch[1 / 50] LR: 9.9e-05
----------
('=====================================', 120, '============================================')

   120/130260 [..............................] - ETA: 12:04 - loss: 3903.8330 * Text to video:
 * r_1_5_10: [0.171, 1.167, 2.133]
 * medr, meanr: [252.0, 250.026]
 * ----------
 * Video to text:
 * r_1_5_10: [0.0, 0.402, 1.207]
 * medr, meanr: [467.0, 764.932]
 * ----------
 * Current perf: 5.08048289738
 * Best perf: 5.33199195171

Epoch[2 / 50] LR: 9.801e-05
----------
('=====================================', 120, '============================================')

   120/130260 [..............................] - ETA: 11:49 - loss: 3833.3901 * Text to video:
 * r_1_5_10: [0.191, 1.046, 2.123]
 * medr, meanr: [253.0, 250.777]
 * ----------
 * Video to text:
 * r_1_5_10: [0.0, 0.201, 1.61]
 * medr, meanr: [487.0, 805.419]
 * ----------
 * Current perf: 5.17102615694
 * Best perf: 5.33199195171

Epoch[3 / 50] LR: 4.851495e-05
----------
('=====================================', 120, '============================================')

   120/130260 [..............................] - ETA: 13:57 - loss: 3754.6067 * Text to video:
 * r_1_5_10: [0.181, 1.036, 2.012]
 * medr, meanr: [252.0, 251.312]
 * ----------
 * Video to text:
 * r_1_5_10: [0.0, 0.402, 1.61]
 * medr, meanr: [526.0, 832.922]
 * ----------
 * Current perf: 5.24144869215
 * Best perf: 5.33199195171

Epoch[4 / 50] LR: 4.80298005e-05
----------
('=====================================', 120, '============================================')

   120/130260 [..............................] - ETA: 11:39 - loss: 3717.1152 * Text to video:
 * r_1_5_10: [0.171, 1.006, 1.952]
 * medr, meanr: [253.0, 251.727]
 * ----------
 * Video to text:
 * r_1_5_10: [0.201, 0.805, 2.012]
 * medr, meanr: [536.0, 873.207]
 * ----------
 * Current perf: 6.14688128773
 * Best perf: 6.14688128773

Epoch[5 / 50] LR: 4.7549502495e-05
----------
('=====================================', 120, '============================================')

   120/130260 [..............................] - ETA: 14:32 - loss: 3684.5183 * Text to video:
 * r_1_5_10: [0.141, 0.996, 2.002]
 * medr, meanr: [254.0, 252.052]
 * ----------
 * Video to text:
 * r_1_5_10: [0.402, 1.006, 2.616]
 * medr, meanr: [529.0, 904.239]
 * ----------
 * Current perf: 7.1629778672
 * Best perf: 7.1629778672

Epoch[6 / 50] LR: 4.70740074701e-05
----------
('=====================================', 120, '============================================')

   120/130260 [..............................] - ETA: 14:26 - loss: 3642.1526 * Text to video:
 * r_1_5_10: [0.101, 1.046, 2.002]
 * medr, meanr: [254.0, 252.257]
 * ----------
 * Video to text:
 * r_1_5_10: [0.0, 1.408, 2.414]
 * medr, meanr: [512.0, 928.602]
 * ----------
 * Current perf: 6.97183098592
 * Best perf: 7.1629778672

Epoch[7 / 50] LR: 2.33016336977e-05
----------
('=====================================', 120, '============================================')

   120/130260 [..............................] - ETA: 13:48 - loss: 3617.3618 * Text to video:
 * r_1_5_10: [0.111, 1.016, 2.012]
 * medr, meanr: [255.0, 252.451]
 * ----------
 * Video to text:
 * r_1_5_10: [0.0, 1.408, 2.213]
 * medr, meanr: [517.0, 945.938]
 * ----------
 * Current perf: 6.76056338028
 * Best perf: 7.1629778672

Epoch[8 / 50] LR: 2.30686173607e-05
----------
('=====================================', 120, '============================================')

   120/130260 [..............................] - ETA: 12:12 - loss: 3592.0654 * Text to video:
 * r_1_5_10: [0.151, 0.996, 2.022]
 * medr, meanr: [255.0, 252.557]
 * ----------
 * Video to text:
 * r_1_5_10: [0.0, 1.207, 2.213]
 * medr, meanr: [516.0, 962.461]
 * ----------
 * Current perf: 6.58953722334
 * Best perf: 7.1629778672

Epoch[9 / 50] LR: 2.28379311871e-05
----------
('=====================================', 120, '============================================')

   120/130260 [..............................] - ETA: 11:28 - loss: 3570.7090 * Text to video:
 * r_1_5_10: [0.161, 0.946, 1.922]
 * medr, meanr: [254.0, 252.671]
 * ----------
 * Video to text:
 * r_1_5_10: [0.0, 0.805, 2.213]
 * medr, meanr: [525.0, 977.258]
 * ----------
 * Current perf: 6.046277666
 * Best perf: 7.1629778672

Epoch[10 / 50] LR: 1.13047759376e-05
----------
('=====================================', 120, '============================================')

   120/130260 [..............................] - ETA: 11:06 - loss: 3549.3855 * Text to video:
 * r_1_5_10: [0.161, 0.936, 1.911]
 * medr, meanr: [255.0, 252.759]
 * ----------
 * Video to text:
 * r_1_5_10: [0.0, 0.805, 1.811]
 * medr, meanr: [517.0, 987.179]
 * ----------
 * Current perf: 5.62374245473
 * Best perf: 7.1629778672

Epoch[11 / 50] LR: 1.11917281782e-05
----------
('=====================================', 120, '============================================')

   120/130260 [..............................] - ETA: 11:21 - loss: 3536.3601 * Text to video:
 * r_1_5_10: [0.151, 0.926, 1.851]
 * medr, meanr: [254.0, 252.816]
 * ----------
 * Video to text:
 * r_1_5_10: [0.0, 0.805, 1.811]
 * medr, meanr: [517.0, 996.783]
 * ----------
 * Current perf: 5.54325955734
 * Best perf: 7.1629778672

Epoch[12 / 50] LR: 1.10798108965e-05
----------
('=====================================', 120, '============================================')

   120/130260 [..............................] - ETA: 11:20 - loss: 3523.8384 * Text to video:
 * r_1_5_10: [0.141, 0.936, 1.801]
 * medr, meanr: [255.0, 252.872]
 * ----------
 * Video to text:
 * r_1_5_10: [0.0, 0.805, 1.811]
 * medr, meanr: [518.0, 1007.926]
 * ----------
 * Current perf: 5.49295774648
 * Best perf: 7.1629778672

Epoch[13 / 50] LR: 5.48450639374e-06
----------
('=====================================', 120, '============================================')

   120/130260 [..............................] - ETA: 11:05 - loss: 3519.9741 * Text to video:
 * r_1_5_10: [0.141, 0.875, 1.831]
 * medr, meanr: [255.0, 252.908]
 * ----------
 * Video to text:
 * r_1_5_10: [0.0, 0.805, 1.61]
 * medr, meanr: [517.0, 1019.107]
 * ----------
 * Current perf: 5.2615694165
 * Best perf: 7.1629778672

Epoch[14 / 50] LR: 5.42966132981e-06
----------
('=====================================', 120, '============================================')

   120/130260 [..............................] - ETA: 12:12 - loss: 3510.8472 * Text to video:
 * r_1_5_10: [0.161, 0.895, 1.851]
 * medr, meanr: [254.0, 252.914]
 * ----------
 * Video to text:
 * r_1_5_10: [0.0, 0.805, 1.207]
 * medr, meanr: [527.0, 1029.815]
 * ----------
 * Current perf: 4.91951710262
 * Best perf: 7.1629778672

Epoch[15 / 50] LR: 5.37536471651e-06
----------
('=====================================', 120, '============================================')

   120/130260 [..............................] - ETA: 11:25 - loss: 3511.2485 * Text to video:
 * r_1_5_10: [0.151, 0.915, 1.901]
 * medr, meanr: [254.0, 252.921]
 * ----------
 * Video to text:
 * r_1_5_10: [0.0, 0.805, 1.207]
 * medr, meanr: [532.0, 1036.964]
 * ----------
 * Current perf: 4.97987927565
 * Best perf: 7.1629778672

Epoch[16 / 50] LR: 2.66080553467e-06
----------
('=====================================', 120, '============================================')

   120/130260 [..............................] - ETA: 11:22 - loss: 3508.8145 * Text to video:
 * r_1_5_10: [0.151, 0.895, 1.932]
 * medr, meanr: [254.0, 252.912]
 * ----------
 * Video to text:
 * r_1_5_10: [0.0, 0.805, 1.006]
 * medr, meanr: [544.0, 1042.702]
 * ----------
 * Current perf: 4.78873239437
 * Best perf: 7.1629778672

Early stopping happended.

best performance on validation: 7.1629778672

<type 'type'>
{
  "checkpoint_name": "model_best.pth.tar", 
  "workers": 5, 
  "rootpath": "../VisualSearch", 
  "batch_size": 128, 
  "log_step": 10, 
  "logger_name": "../VisualSearch/msrvtt10ktrain/cvpr_2019/msrvtt10kval/dual_encoding_concate_full_dp_0.2_measure_exp/vocab_word_vocab_5_word_dim_500_text_rnn_size_512_text_norm_True_kernel_sizes_2-3-4_num_512/visual_feature_resnet-152-img1k-flatten0_outputos_visual_rnn_size_1024_visual_norm_True_kernel_sizes_2-3-4-5_num_512/mapping_text_0-2048_img_0-2048/loss_func_cont_margin_0.2_direction_all_max_violation_True_cost_style_sum/optimizer_adam_lr_0.0001_decay_0.99_grad_clip_2.0_val_metric_recall/runs_0", 
  "testCollection": "msrvtt10ktest", 
  "n_caption": 20, 
  "overwrite": 1
}
=> loaded checkpoint '../VisualSearch/msrvtt10ktrain/cvpr_2019/msrvtt10kval/dual_encoding_concate_full_dp_0.2_measure_exp/vocab_word_vocab_5_word_dim_500_text_rnn_size_512_text_norm_True_kernel_sizes_2-3-4_num_512/visual_feature_resnet-152-img1k-flatten0_outputos_visual_rnn_size_1024_visual_norm_True_kernel_sizes_2-3-4-5_num_512/mapping_text_0-2048_img_0-2048/loss_func_cont_margin_0.2_direction_all_max_violation_True_cost_style_sum/optimizer_adam_lr_0.0001_decay_0.99_grad_clip_2.0_val_metric_recall/runs_0/model_best.pth.tar' (epoch 6, best_rsum 7.1629778672)
../VisualSearch/msrvtt10ktest/results/msrvtt10ktrain/msrvtt10kval/dual_encoding_concate_full_dp_0.2_measure_exp/vocab_word_vocab_5_word_dim_500_text_rnn_size_512_text_norm_True_kernel_sizes_2-3-4_num_512/visual_feature_resnet-152-img1k-flatten0_outputos_visual_rnn_size_1024_visual_norm_True_kernel_sizes_2-3-4-5_num_512/mapping_text_0-2048_img_0-2048/loss_func_cont_margin_0.2_direction_all_max_violation_True_cost_style_sum/optimizer_adam_lr_0.0001_decay_0.99_grad_clip_2.0_val_metric_recall/runs_0/model_best.pth.tar/pred_errors_matrix.pth.tar exists.
overwrite
[BigFile] 305462x2048 instances loaded from ../VisualSearch/msrvtt10ktest/FeatureData/resnet-152-img1k-flatten0_outputos
>>>>>>>>>>>>>>>>>>>>
Contrastive Loss Used
write into: ../VisualSearch/msrvtt10ktest/results/msrvtt10ktrain/msrvtt10kval/dual_encoding_concate_full_dp_0.2_measure_exp/vocab_word_vocab_5_word_dim_500_text_rnn_size_512_text_norm_True_kernel_sizes_2-3-4_num_512/visual_feature_resnet-152-img1k-flatten0_outputos_visual_rnn_size_1024_visual_norm_True_kernel_sizes_2-3-4-5_num_512/mapping_text_0-2048_img_0-2048/loss_func_cont_margin_0.2_direction_all_max_violation_True_cost_style_sum/optimizer_adam_lr_0.0001_decay_0.99_grad_clip_2.0_val_metric_recall/runs_0/model_best.pth.tar/pred_errors_matrix.pth.tar
 * Text to Video:
 * r_1_5_10, medr, meanr: [0.0, 0.1, 0.2, 1577.0, 1555.4]
 * recall sum: 0.3
 * mAP: 0.002
 * ----------
 * Video to text:
 * r_1_5_10, medr, meanr: [0.1, 0.2, 0.2, 3739.0, 6135.7]
 * recall sum: 0.4
 * mAP: 0.0
 * ----------
