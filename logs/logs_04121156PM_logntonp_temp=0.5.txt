<type 'type'>
{
  "grad_clip": 2, 
  "word_dim": 500, 
  "text_mapping_layers": "0-2048", 
  "num_epochs": 50, 
  "dataset": "msrvtt", 
  "logtimestamp": "04121156PM_logntonp_temp=0.5", 
  "text_kernel_sizes": "2-3-4", 
  "measure": "exp", 
  "lr_decay_rate": 0.99, 
  "n_caption": 20, 
  "overwrite": 1, 
  "workers": 4, 
  "text_norm": true, 
  "neg_sampling": "default", 
  "log_step": 10, 
  "visual_norm": true, 
  "max_violation": true, 
  "visual_feature": "resnet-152-img1k-flatten0_outputos", 
  "trainCollection": "msrvtt10ktrain", 
  "learning_rate": 0.0001, 
  "batch_padding": 0, 
  "direction": "all", 
  "optimizer": "adam", 
  "resume": null, 
  "dropout": 0.2, 
  "visual_kernel_num": 512, 
  "rootpath": "../VisualSearch", 
  "batch_size": 128, 
  "cv_name": "cvpr_2019", 
  "text_kernel_num": 512, 
  "testCollection": "msrvtt10ktest", 
  "visual_mapping_layers": "0-2048", 
  "cost_style": "sum", 
  "text_rnn_size": 512, 
  "vocab": "word_vocab_5", 
  "loss_fun": "cont", 
  "visual_rnn_size": 1024, 
  "visual_kernel_sizes": "2-3-4-5", 
  "concate": "full", 
  "postfix": "runs_0", 
  "val_metric": "recall", 
  "valCollection": "msrvtt10kval", 
  "model": "dual_encoding", 
  "margin": 0.2
}
../VisualSearch/msrvtt10ktrain/cvpr_2019/msrvtt10kval/dual_encoding_concate_full_dp_0.2_measure_exp/vocab_word_vocab_5_word_dim_500_text_rnn_size_512_text_norm_True_kernel_sizes_2-3-4_num_512/visual_feature_resnet-152-img1k-flatten0_outputos_visual_rnn_size_1024_visual_norm_True_kernel_sizes_2-3-4-5_num_512/mapping_text_0-2048_img_0-2048/loss_func_cont_margin_0.2_direction_all_max_violation_True_cost_style_sum/optimizer_adam_lr_0.0001_decay_0.99_grad_clip_2.0_val_metric_recall/runs_0
../VisualSearch/msrvtt10ktrain/cvpr_2019/msrvtt10kval/dual_encoding_concate_full_dp_0.2_measure_exp/vocab_word_vocab_5_word_dim_500_text_rnn_size_512_text_norm_True_kernel_sizes_2-3-4_num_512/visual_feature_resnet-152-img1k-flatten0_outputos_visual_rnn_size_1024_visual_norm_True_kernel_sizes_2-3-4-5_num_512/mapping_text_0-2048_img_0-2048/loss_func_cont_margin_0.2_direction_all_max_violation_True_cost_style_sum/optimizer_adam_lr_0.0001_decay_0.99_grad_clip_2.0_val_metric_recall/runs_0/model_best.pth.tar exists.
overwrite
../VisualSearch/msrvtt10ktrain/cvpr_2019/msrvtt10kval/dual_encoding_concate_full_dp_0.2_measure_exp/vocab_word_vocab_5_word_dim_500_text_rnn_size_512_text_norm_True_kernel_sizes_2-3-4_num_512/visual_feature_resnet-152-img1k-flatten0_outputos_visual_rnn_size_1024_visual_norm_True_kernel_sizes_2-3-4-5_num_512/mapping_text_0-2048_img_0-2048/loss_func_cont_margin_0.2_direction_all_max_violation_True_cost_style_sum/optimizer_adam_lr_0.0001_decay_0.99_grad_clip_2.0_val_metric_recall/runs_0/val_metric.txt exists.
overwrite
[BigFile] 305462x2048 instances loaded from ../VisualSearch/msrvtt10ktrain/FeatureData/resnet-152-img1k-flatten0_outputos
[BigFile] 305462x2048 instances loaded from ../VisualSearch/msrvtt10kval/FeatureData/resnet-152-img1k-flatten0_outputos
[BigFile] 1743364x500 instances loaded from ../VisualSearch/word2vec/flickr/vec500flickr30m
('getting pre-trained parameter for word embedding initialization', (7811, 500))
=======================Data Loaded=================================
>>>>>>>>>>>>>>>>>>>>
Contrastive Loss Used
Epoch[0 / 50] LR: 0.0001
----------
Using cap_ids

   128/130260 [..............................] - ETA: 1:04:20 - loss: -0.0081Using cap_ids
<type 'type'>
{
  "checkpoint_name": "model_best.pth.tar", 
  "workers": 5, 
  "rootpath": "../VisualSearch", 
  "batch_size": 128, 
  "log_step": 10, 
  "logger_name": "../VisualSearch/msrvtt10ktrain/cvpr_2019/msrvtt10kval/dual_encoding_concate_full_dp_0.2_measure_exp/vocab_word_vocab_5_word_dim_500_text_rnn_size_512_text_norm_True_kernel_sizes_2-3-4_num_512/visual_feature_resnet-152-img1k-flatten0_outputos_visual_rnn_size_1024_visual_norm_True_kernel_sizes_2-3-4-5_num_512/mapping_text_0-2048_img_0-2048/loss_func_cont_margin_0.2_direction_all_max_violation_True_cost_style_sum/optimizer_adam_lr_0.0001_decay_0.99_grad_clip_2.0_val_metric_recall/runs_0", 
  "testCollection": "msrvtt10ktest", 
  "n_caption": 20, 
  "overwrite": 1
}
=> loaded checkpoint '../VisualSearch/msrvtt10ktrain/cvpr_2019/msrvtt10kval/dual_encoding_concate_full_dp_0.2_measure_exp/vocab_word_vocab_5_word_dim_500_text_rnn_size_512_text_norm_True_kernel_sizes_2-3-4_num_512/visual_feature_resnet-152-img1k-flatten0_outputos_visual_rnn_size_1024_visual_norm_True_kernel_sizes_2-3-4-5_num_512/mapping_text_0-2048_img_0-2048/loss_func_cont_margin_0.2_direction_all_max_violation_True_cost_style_sum/optimizer_adam_lr_0.0001_decay_0.99_grad_clip_2.0_val_metric_recall/runs_0/model_best.pth.tar' (epoch 6, best_rsum 135.050301811)
../VisualSearch/msrvtt10ktest/results/msrvtt10ktrain/msrvtt10kval/dual_encoding_concate_full_dp_0.2_measure_exp/vocab_word_vocab_5_word_dim_500_text_rnn_size_512_text_norm_True_kernel_sizes_2-3-4_num_512/visual_feature_resnet-152-img1k-flatten0_outputos_visual_rnn_size_1024_visual_norm_True_kernel_sizes_2-3-4-5_num_512/mapping_text_0-2048_img_0-2048/loss_func_cont_margin_0.2_direction_all_max_violation_True_cost_style_sum/optimizer_adam_lr_0.0001_decay_0.99_grad_clip_2.0_val_metric_recall/runs_0/model_best.pth.tar/pred_errors_matrix.pth.tar exists.
overwrite
[BigFile] 305462x2048 instances loaded from ../VisualSearch/msrvtt10ktest/FeatureData/resnet-152-img1k-flatten0_outputos
>>>>>>>>>>>>>>>>>>>>
Contrastive Loss Used
write into: ../VisualSearch/msrvtt10ktest/results/msrvtt10ktrain/msrvtt10kval/dual_encoding_concate_full_dp_0.2_measure_exp/vocab_word_vocab_5_word_dim_500_text_rnn_size_512_text_norm_True_kernel_sizes_2-3-4_num_512/visual_feature_resnet-152-img1k-flatten0_outputos_visual_rnn_size_1024_visual_norm_True_kernel_sizes_2-3-4-5_num_512/mapping_text_0-2048_img_0-2048/loss_func_cont_margin_0.2_direction_all_max_violation_True_cost_style_sum/optimizer_adam_lr_0.0001_decay_0.99_grad_clip_2.0_val_metric_recall/runs_0/model_best.pth.tar/pred_errors_matrix.pth.tar
 * Text to Video:
 * r_1_5_10, medr, meanr: [1.6, 6.4, 10.7, 118.0, 309.3]
 * recall sum: 18.7
 * mAP: 0.051
 * ----------
 * Video to text:
 * r_1_5_10, medr, meanr: [2.2, 7.4, 12.2, 126.0, 859.1]
 * recall sum: 21.8
 * mAP: 0.014
 * ----------
