{
  "threshold": 5, 
  "text_style": "bow", 
  "rootpath": "../VisualSearch", 
  "collection": "msrvtt10ktrain", 
  "overwrite": 0
}
../VisualSearch/msrvtt10ktrain/TextData/vocabulary/bow/word_vocab_5.pkl exists.
skip
{
  "threshold": 5, 
  "text_style": "rnn", 
  "rootpath": "../VisualSearch", 
  "collection": "msrvtt10ktrain", 
  "overwrite": 0
}
../VisualSearch/msrvtt10ktrain/TextData/vocabulary/rnn/word_vocab_5.pkl exists.
skip
<type 'type'>
{
  "grad_clip": 2, 
  "word_dim": 500, 
  "text_mapping_layers": "0-2048", 
  "num_epochs": 50, 
  "dataset": "msrvtt", 
  "text_kernel_sizes": "2-3-4", 
  "measure": "exp", 
  "lr_decay_rate": 0.99, 
  "n_caption": 20, 
  "overwrite": 1, 
  "workers": 5, 
  "text_norm": true, 
  "neg_sampling": "default", 
  "log_step": 10, 
  "visual_norm": true, 
  "max_violation": true, 
  "visual_feature": "resnet-152-img1k-flatten0_outputos", 
  "trainCollection": "msrvtt10ktrain", 
  "learning_rate": 0.0001, 
  "batch_padding": 0, 
  "direction": "all", 
  "optimizer": "adam", 
  "resume": "", 
  "dropout": 0.2, 
  "visual_kernel_num": 512, 
  "rootpath": "../VisualSearch", 
  "batch_size": 120, 
  "cv_name": "cvpr_2019", 
  "text_kernel_num": 512, 
  "testCollection": "msrvtt10ktest", 
  "visual_mapping_layers": "0-2048", 
  "cost_style": "sum", 
  "text_rnn_size": 512, 
  "vocab": "word_vocab_5", 
  "loss_fun": "cont", 
  "visual_rnn_size": 1024, 
  "visual_kernel_sizes": "2-3-4-5", 
  "concate": "full", 
  "postfix": "runs_0", 
  "val_metric": "recall", 
  "valCollection": "msrvtt10kval", 
  "model": "dual_encoding", 
  "margin": 0.2
}
../VisualSearch/msrvtt10ktrain/cvpr_2019/msrvtt10kval/dual_encoding_concate_full_dp_0.2_measure_exp/vocab_word_vocab_5_word_dim_500_text_rnn_size_512_text_norm_True_kernel_sizes_2-3-4_num_512/visual_feature_resnet-152-img1k-flatten0_outputos_visual_rnn_size_1024_visual_norm_True_kernel_sizes_2-3-4-5_num_512/mapping_text_0-2048_img_0-2048/loss_func_cont_margin_0.2_direction_all_max_violation_True_cost_style_sum/optimizer_adam_lr_0.0001_decay_0.99_grad_clip_2.0_val_metric_recall/runs_0
../VisualSearch/msrvtt10ktrain/cvpr_2019/msrvtt10kval/dual_encoding_concate_full_dp_0.2_measure_exp/vocab_word_vocab_5_word_dim_500_text_rnn_size_512_text_norm_True_kernel_sizes_2-3-4_num_512/visual_feature_resnet-152-img1k-flatten0_outputos_visual_rnn_size_1024_visual_norm_True_kernel_sizes_2-3-4-5_num_512/mapping_text_0-2048_img_0-2048/loss_func_cont_margin_0.2_direction_all_max_violation_True_cost_style_sum/optimizer_adam_lr_0.0001_decay_0.99_grad_clip_2.0_val_metric_recall/runs_0/model_best.pth.tar exists.
overwrite
../VisualSearch/msrvtt10ktrain/cvpr_2019/msrvtt10kval/dual_encoding_concate_full_dp_0.2_measure_exp/vocab_word_vocab_5_word_dim_500_text_rnn_size_512_text_norm_True_kernel_sizes_2-3-4_num_512/visual_feature_resnet-152-img1k-flatten0_outputos_visual_rnn_size_1024_visual_norm_True_kernel_sizes_2-3-4-5_num_512/mapping_text_0-2048_img_0-2048/loss_func_cont_margin_0.2_direction_all_max_violation_True_cost_style_sum/optimizer_adam_lr_0.0001_decay_0.99_grad_clip_2.0_val_metric_recall/runs_0/val_metric.txt exists.
overwrite
[BigFile] 305462x2048 instances loaded from ../VisualSearch/msrvtt10ktrain/FeatureData/resnet-152-img1k-flatten0_outputos
[BigFile] 305462x2048 instances loaded from ../VisualSearch/msrvtt10kval/FeatureData/resnet-152-img1k-flatten0_outputos
[BigFile] 1743364x500 instances loaded from ../VisualSearch/word2vec/flickr/vec500flickr30m
('getting pre-trained parameter for word embedding initialization', (7811, 500))
=======================Data Loaded=================================
>>>>>>>>>>>>>>>>>>>>
Contrastive Loss Used
Epoch[0 / 50] LR: 0.0001
----------

   120/130260 [..............................] - ETA: 47:29 - loss: 1.9841 * Text to video:
 * r_1_5_10: [0.272, 1.016, 2.213]
 * medr, meanr: [240.0, 243.59]
 * ----------
 * Video to text:
 * r_1_5_10: [0.201, 1.207, 2.817]
 * medr, meanr: [421.0, 736.905]
 * ----------
 * Current perf: 7.72635814889
 * Best perf: 7.72635814889

Epoch[1 / 50] LR: 9.9e-05
----------

   120/130260 [..............................] - ETA: 15:15 - loss: 1.9841 * Text to video:
 * r_1_5_10: [0.241, 1.046, 2.254]
 * medr, meanr: [238.0, 241.151]
 * ----------
 * Video to text:
 * r_1_5_10: [0.201, 1.207, 2.414]
 * medr, meanr: [388.0, 722.402]
 * ----------
 * Current perf: 7.36418511066
 * Best perf: 7.72635814889

Epoch[2 / 50] LR: 9.801e-05
----------

   120/130260 [..............................] - ETA: 12:00 - loss: 1.9839 * Text to video:
 * r_1_5_10: [0.231, 1.066, 2.364]
 * medr, meanr: [239.0, 241.006]
 * ----------
 * Video to text:
 * r_1_5_10: [0.402, 1.61, 2.414]
 * medr, meanr: [390.0, 712.738]
 * ----------
 * Current perf: 8.08853118712
 * Best perf: 8.08853118712

Epoch[3 / 50] LR: 9.70299e-05
----------

   120/130260 [..............................] - ETA: 13:07 - loss: 1.9837 * Text to video:
 * r_1_5_10: [0.252, 1.087, 2.314]
 * medr, meanr: [238.0, 240.483]
 * ----------
 * Video to text:
 * r_1_5_10: [0.402, 1.811, 3.018]
 * medr, meanr: [377.0, 679.344]
 * ----------
 * Current perf: 8.88329979879
 * Best perf: 8.88329979879

Epoch[4 / 50] LR: 9.6059601e-05
----------

   120/130260 [..............................] - ETA: 15:32 - loss: 1.9836 * Text to video:
 * r_1_5_10: [0.252, 1.097, 2.284]
 * medr, meanr: [236.0, 239.851]
 * ----------
 * Video to text:
 * r_1_5_10: [0.201, 1.61, 2.817]
 * medr, meanr: [402.0, 658.378]
 * ----------
 * Current perf: 8.25955734406
 * Best perf: 8.88329979879

Epoch[5 / 50] LR: 4.7549502495e-05
----------

   120/130260 [..............................] - ETA: 11:59 - loss: 1.9836 * Text to video:
 * r_1_5_10: [0.231, 1.036, 2.384]
 * medr, meanr: [235.0, 238.873]
 * ----------
 * Video to text:
 * r_1_5_10: [0.201, 1.61, 2.817]
 * medr, meanr: [383.0, 646.404]
 * ----------
 * Current perf: 8.27967806841
 * Best perf: 8.88329979879

Epoch[6 / 50] LR: 4.70740074701e-05
----------

   120/130260 [..............................] - ETA: 12:05 - loss: 1.9838 * Text to video:
 * r_1_5_10: [0.262, 1.127, 2.304]
 * medr, meanr: [234.0, 238.365]
 * ----------
 * Video to text:
 * r_1_5_10: [0.201, 1.61, 2.817]
 * medr, meanr: [390.0, 646.105]
 * ----------
 * Current perf: 8.3199195171
 * Best perf: 8.88329979879

Epoch[7 / 50] LR: 4.66032673953e-05
----------

   120/130260 [..............................] - ETA: 15:07 - loss: 1.9834 * Text to video:
 * r_1_5_10: [0.241, 1.137, 2.324]
 * medr, meanr: [234.0, 237.941]
 * ----------
 * Video to text:
 * r_1_5_10: [0.402, 1.408, 2.817]
 * medr, meanr: [398.0, 652.445]
 * ----------
 * Current perf: 8.32997987928
 * Best perf: 8.88329979879

Epoch[8 / 50] LR: 2.30686173607e-05
----------

   120/130260 [..............................] - ETA: 13:01 - loss: 1.9828 * Text to video:
 * r_1_5_10: [0.262, 1.137, 2.374]
 * medr, meanr: [233.0, 237.796]
 * ----------
 * Video to text:
 * r_1_5_10: [0.402, 1.408, 2.414]
 * medr, meanr: [395.0, 652.602]
 * ----------
 * Current perf: 7.99798792757
 * Best perf: 8.88329979879

Epoch[9 / 50] LR: 2.28379311871e-05
----------

   120/130260 [..............................] - ETA: 12:04 - loss: 1.9833 * Text to video:
 * r_1_5_10: [0.282, 1.127, 2.334]
 * medr, meanr: [233.0, 237.695]
 * ----------
 * Video to text:
 * r_1_5_10: [0.604, 1.408, 2.817]
 * medr, meanr: [391.0, 657.304]
 * ----------
 * Current perf: 8.57142857143
 * Best perf: 8.88329979879

Epoch[10 / 50] LR: 2.26095518752e-05
----------

   120/130260 [..............................] - ETA: 12:11 - loss: 1.9837 * Text to video:
 * r_1_5_10: [0.282, 1.107, 2.334]
 * medr, meanr: [234.0, 237.598]
 * ----------
 * Video to text:
 * r_1_5_10: [0.402, 1.408, 2.616]
 * medr, meanr: [399.0, 662.857]
 * ----------
 * Current perf: 8.14889336016
 * Best perf: 8.88329979879

Epoch[11 / 50] LR: 1.11917281782e-05
----------

   120/130260 [..............................] - ETA: 14:47 - loss: 1.9829 * Text to video:
 * r_1_5_10: [0.272, 1.107, 2.374]
 * medr, meanr: [234.0, 237.564]
 * ----------
 * Video to text:
 * r_1_5_10: [0.201, 1.408, 2.213]
 * medr, meanr: [415.0, 668.256]
 * ----------
 * Current perf: 7.5754527163
 * Best perf: 8.88329979879

Epoch[12 / 50] LR: 1.10798108965e-05
----------

   120/130260 [..............................] - ETA: 15:09 - loss: 1.9830 * Text to video:
 * r_1_5_10: [0.282, 1.117, 2.364]
 * medr, meanr: [233.0, 237.554]
 * ----------
 * Video to text:
 * r_1_5_10: [0.201, 1.408, 2.012]
 * medr, meanr: [419.0, 674.608]
 * ----------
 * Current perf: 7.38430583501
 * Best perf: 8.88329979879

Epoch[13 / 50] LR: 1.09690127875e-05
----------

   120/130260 [..............................] - ETA: 14:58 - loss: 1.9834 * Text to video:
 * r_1_5_10: [0.272, 1.177, 2.394]
 * medr, meanr: [232.0, 237.492]
 * ----------
 * Video to text:
 * r_1_5_10: [0.201, 1.408, 1.811]
 * medr, meanr: [421.0, 679.437]
 * ----------
 * Current perf: 7.26358148893
 * Best perf: 8.88329979879

Epoch[14 / 50] LR: 5.42966132981e-06
----------

   120/130260 [..............................] - ETA: 12:39 - loss: 1.9830 * Text to video:
 * r_1_5_10: [0.262, 1.227, 2.425]
 * medr, meanr: [231.0, 237.485]
 * ----------
 * Video to text:
 * r_1_5_10: [0.201, 1.408, 1.811]
 * medr, meanr: [414.0, 681.435]
 * ----------
 * Current perf: 7.33400402414
 * Best perf: 8.88329979879

Early stopping happended.

best performance on validation: 8.88329979879

<type 'type'>
{
  "checkpoint_name": "model_best.pth.tar", 
  "workers": 5, 
  "rootpath": "../VisualSearch", 
  "batch_size": 128, 
  "log_step": 10, 
  "logger_name": "../VisualSearch/msrvtt10ktrain/cvpr_2019/msrvtt10kval/dual_encoding_concate_full_dp_0.2_measure_exp/vocab_word_vocab_5_word_dim_500_text_rnn_size_512_text_norm_True_kernel_sizes_2-3-4_num_512/visual_feature_resnet-152-img1k-flatten0_outputos_visual_rnn_size_1024_visual_norm_True_kernel_sizes_2-3-4-5_num_512/mapping_text_0-2048_img_0-2048/loss_func_cont_margin_0.2_direction_all_max_violation_True_cost_style_sum/optimizer_adam_lr_0.0001_decay_0.99_grad_clip_2.0_val_metric_recall/runs_0", 
  "testCollection": "msrvtt10ktest", 
  "n_caption": 20, 
  "overwrite": 1
}
=> loaded checkpoint '../VisualSearch/msrvtt10ktrain/cvpr_2019/msrvtt10kval/dual_encoding_concate_full_dp_0.2_measure_exp/vocab_word_vocab_5_word_dim_500_text_rnn_size_512_text_norm_True_kernel_sizes_2-3-4_num_512/visual_feature_resnet-152-img1k-flatten0_outputos_visual_rnn_size_1024_visual_norm_True_kernel_sizes_2-3-4-5_num_512/mapping_text_0-2048_img_0-2048/loss_func_cont_margin_0.2_direction_all_max_violation_True_cost_style_sum/optimizer_adam_lr_0.0001_decay_0.99_grad_clip_2.0_val_metric_recall/runs_0/model_best.pth.tar' (epoch 4, best_rsum 8.88329979879)
../VisualSearch/msrvtt10ktest/results/msrvtt10ktrain/msrvtt10kval/dual_encoding_concate_full_dp_0.2_measure_exp/vocab_word_vocab_5_word_dim_500_text_rnn_size_512_text_norm_True_kernel_sizes_2-3-4_num_512/visual_feature_resnet-152-img1k-flatten0_outputos_visual_rnn_size_1024_visual_norm_True_kernel_sizes_2-3-4-5_num_512/mapping_text_0-2048_img_0-2048/loss_func_cont_margin_0.2_direction_all_max_violation_True_cost_style_sum/optimizer_adam_lr_0.0001_decay_0.99_grad_clip_2.0_val_metric_recall/runs_0/model_best.pth.tar/pred_errors_matrix.pth.tar exists.
overwrite
[BigFile] 305462x2048 instances loaded from ../VisualSearch/msrvtt10ktest/FeatureData/resnet-152-img1k-flatten0_outputos
>>>>>>>>>>>>>>>>>>>>
Contrastive Loss Used
write into: ../VisualSearch/msrvtt10ktest/results/msrvtt10ktrain/msrvtt10kval/dual_encoding_concate_full_dp_0.2_measure_exp/vocab_word_vocab_5_word_dim_500_text_rnn_size_512_text_norm_True_kernel_sizes_2-3-4_num_512/visual_feature_resnet-152-img1k-flatten0_outputos_visual_rnn_size_1024_visual_norm_True_kernel_sizes_2-3-4-5_num_512/mapping_text_0-2048_img_0-2048/loss_func_cont_margin_0.2_direction_all_max_violation_True_cost_style_sum/optimizer_adam_lr_0.0001_decay_0.99_grad_clip_2.0_val_metric_recall/runs_0/model_best.pth.tar/pred_errors_matrix.pth.tar
 * Text to Video:
 * r_1_5_10, medr, meanr: [0.0, 0.2, 0.5, 1409.0, 1433.3]
 * recall sum: 0.7
 * mAP: 0.003
 * ----------
 * Video to text:
 * r_1_5_10, medr, meanr: [0.1, 0.2, 0.2, 2591.0, 4359.1]
 * recall sum: 0.5
 * mAP: 0.001
 * ----------
