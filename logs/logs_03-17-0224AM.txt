{
  "threshold": 5, 
  "text_style": "bow", 
  "rootpath": "../VisualSearch", 
  "collection": "msrvtt10ktrain", 
  "overwrite": 0
}
../VisualSearch/msrvtt10ktrain/TextData/vocabulary/bow/word_vocab_5.pkl exists.
skip
{
  "threshold": 5, 
  "text_style": "rnn", 
  "rootpath": "../VisualSearch", 
  "collection": "msrvtt10ktrain", 
  "overwrite": 0
}
../VisualSearch/msrvtt10ktrain/TextData/vocabulary/rnn/word_vocab_5.pkl exists.
skip
<type 'type'>
{
  "grad_clip": 2, 
  "word_dim": 500, 
  "text_mapping_layers": "0-2048", 
  "num_epochs": 50, 
  "dataset": "msrvtt", 
  "text_kernel_sizes": "2-3-4", 
  "measure": "exp", 
  "lr_decay_rate": 0.99, 
  "n_caption": 20, 
  "overwrite": 1, 
  "workers": 5, 
  "text_norm": true, 
  "neg_sampling": "default", 
  "log_step": 10, 
  "visual_norm": true, 
  "max_violation": true, 
  "visual_feature": "resnet-152-img1k-flatten0_outputos", 
  "trainCollection": "msrvtt10ktrain", 
  "learning_rate": 0.0001, 
  "batch_padding": 0, 
  "direction": "all", 
  "optimizer": "adam", 
  "resume": "", 
  "dropout": 0.2, 
  "visual_kernel_num": 512, 
  "rootpath": "../VisualSearch", 
  "batch_size": 120, 
  "cv_name": "cvpr_2019", 
  "text_kernel_num": 512, 
  "testCollection": "msrvtt10ktest", 
  "visual_mapping_layers": "0-2048", 
  "cost_style": "sum", 
  "text_rnn_size": 512, 
  "vocab": "word_vocab_5", 
  "loss_fun": "cont", 
  "visual_rnn_size": 1024, 
  "visual_kernel_sizes": "2-3-4-5", 
  "concate": "full", 
  "postfix": "runs_0", 
  "val_metric": "recall", 
  "valCollection": "msrvtt10kval", 
  "model": "dual_encoding", 
  "margin": 0.2
}
../VisualSearch/msrvtt10ktrain/cvpr_2019/msrvtt10kval/dual_encoding_concate_full_dp_0.2_measure_exp/vocab_word_vocab_5_word_dim_500_text_rnn_size_512_text_norm_True_kernel_sizes_2-3-4_num_512/visual_feature_resnet-152-img1k-flatten0_outputos_visual_rnn_size_1024_visual_norm_True_kernel_sizes_2-3-4-5_num_512/mapping_text_0-2048_img_0-2048/loss_func_cont_margin_0.2_direction_all_max_violation_True_cost_style_sum/optimizer_adam_lr_0.0001_decay_0.99_grad_clip_2.0_val_metric_recall/runs_0
../VisualSearch/msrvtt10ktrain/cvpr_2019/msrvtt10kval/dual_encoding_concate_full_dp_0.2_measure_exp/vocab_word_vocab_5_word_dim_500_text_rnn_size_512_text_norm_True_kernel_sizes_2-3-4_num_512/visual_feature_resnet-152-img1k-flatten0_outputos_visual_rnn_size_1024_visual_norm_True_kernel_sizes_2-3-4-5_num_512/mapping_text_0-2048_img_0-2048/loss_func_cont_margin_0.2_direction_all_max_violation_True_cost_style_sum/optimizer_adam_lr_0.0001_decay_0.99_grad_clip_2.0_val_metric_recall/runs_0/model_best.pth.tar exists.
overwrite
../VisualSearch/msrvtt10ktrain/cvpr_2019/msrvtt10kval/dual_encoding_concate_full_dp_0.2_measure_exp/vocab_word_vocab_5_word_dim_500_text_rnn_size_512_text_norm_True_kernel_sizes_2-3-4_num_512/visual_feature_resnet-152-img1k-flatten0_outputos_visual_rnn_size_1024_visual_norm_True_kernel_sizes_2-3-4-5_num_512/mapping_text_0-2048_img_0-2048/loss_func_cont_margin_0.2_direction_all_max_violation_True_cost_style_sum/optimizer_adam_lr_0.0001_decay_0.99_grad_clip_2.0_val_metric_recall/runs_0/val_metric.txt exists.
overwrite
[BigFile] 305462x2048 instances loaded from ../VisualSearch/msrvtt10ktrain/FeatureData/resnet-152-img1k-flatten0_outputos
[BigFile] 305462x2048 instances loaded from ../VisualSearch/msrvtt10kval/FeatureData/resnet-152-img1k-flatten0_outputos
[BigFile] 1743364x500 instances loaded from ../VisualSearch/word2vec/flickr/vec500flickr30m
('getting pre-trained parameter for word embedding initialization', (7811, 500))
=======================Data Loaded=================================
>>>>>>>>>>>>>>>>>>>>
Contrastive Loss Used
Epoch[0 / 50] LR: 0.0001
----------

   120/130260 [..............................] - ETA: 47:11 - loss: 1.2779 * Text to video:
 * r_1_5_10: [0.151, 0.855, 1.821]
 * medr, meanr: [255.0, 252.485]
 * ----------
 * Video to text:
 * r_1_5_10: [0.201, 1.408, 2.012]
 * medr, meanr: [498.0, 841.3]
 * ----------
 * Current perf: 6.44869215292
 * Best perf: 6.44869215292

Epoch[1 / 50] LR: 9.9e-05
----------

   120/130260 [..............................] - ETA: 15:24 - loss: 1.2715 * Text to video:
 * r_1_5_10: [0.091, 0.795, 1.489]
 * medr, meanr: [254.0, 253.048]
 * ----------
 * Video to text:
 * r_1_5_10: [0.0, 0.604, 2.213]
 * medr, meanr: [478.0, 813.654]
 * ----------
 * Current perf: 5.19114688129
 * Best perf: 6.44869215292

Epoch[2 / 50] LR: 9.801e-05
----------

   120/130260 [..............................] - ETA: 12:19 - loss: 1.2669 * Text to video:
 * r_1_5_10: [0.091, 0.795, 1.59]
 * medr, meanr: [254.0, 253.257]
 * ----------
 * Video to text:
 * r_1_5_10: [0.0, 0.402, 1.207]
 * medr, meanr: [519.0, 835.153]
 * ----------
 * Current perf: 4.08450704225
 * Best perf: 6.44869215292

Epoch[3 / 50] LR: 4.851495e-05
----------

   120/130260 [..............................] - ETA: 12:06 - loss: 1.2619 * Text to video:
 * r_1_5_10: [0.08, 0.724, 1.569]
 * medr, meanr: [254.0, 253.715]
 * ----------
 * Video to text:
 * r_1_5_10: [0.0, 0.201, 0.805]
 * medr, meanr: [537.0, 868.99]
 * ----------
 * Current perf: 3.38028169014
 * Best perf: 6.44869215292

Epoch[4 / 50] LR: 4.80298005e-05
----------

   120/130260 [..............................] - ETA: 12:05 - loss: 1.2598 * Text to video:
 * r_1_5_10: [0.091, 0.755, 1.519]
 * medr, meanr: [255.0, 254.222]
 * ----------
 * Video to text:
 * r_1_5_10: [0.0, 0.402, 1.207]
 * medr, meanr: [568.0, 899.59]
 * ----------
 * Current perf: 3.97384305835
 * Best perf: 6.44869215292

Epoch[5 / 50] LR: 4.7549502495e-05
----------

   120/130260 [..............................] - ETA: 11:55 - loss: 1.2569 * Text to video:
 * r_1_5_10: [0.08, 0.755, 1.499]
 * medr, meanr: [258.0, 254.733]
 * ----------
 * Video to text:
 * r_1_5_10: [0.0, 0.402, 1.006]
 * medr, meanr: [565.0, 936.024]
 * ----------
 * Current perf: 3.74245472837
 * Best perf: 6.44869215292

Epoch[6 / 50] LR: 2.3537003735e-05
----------

   120/130260 [..............................] - ETA: 13:57 - loss: 1.2542 * Text to video:
 * r_1_5_10: [0.07, 0.714, 1.459]
 * medr, meanr: [258.0, 255.089]
 * ----------
 * Video to text:
 * r_1_5_10: [0.201, 0.604, 1.207]
 * medr, meanr: [593.0, 962.586]
 * ----------
 * Current perf: 4.2555331992
 * Best perf: 6.44869215292

Epoch[7 / 50] LR: 2.33016336977e-05
----------

   120/130260 [..............................] - ETA: 12:30 - loss: 1.2534 * Text to video:
 * r_1_5_10: [0.07, 0.714, 1.479]
 * medr, meanr: [258.0, 255.414]
 * ----------
 * Video to text:
 * r_1_5_10: [0.0, 0.604, 1.006]
 * medr, meanr: [620.0, 983.809]
 * ----------
 * Current perf: 3.87323943662
 * Best perf: 6.44869215292

Epoch[8 / 50] LR: 2.30686173607e-05
----------

   120/130260 [..............................] - ETA: 12:45 - loss: 1.2515 * Text to video:
 * r_1_5_10: [0.07, 0.724, 1.449]
 * medr, meanr: [257.0, 255.686]
 * ----------
 * Video to text:
 * r_1_5_10: [0.0, 0.604, 1.408]
 * medr, meanr: [622.0, 1004.915]
 * ----------
 * Current perf: 4.2555331992
 * Best perf: 6.44869215292

Epoch[9 / 50] LR: 1.14189655935e-05
----------

   120/130260 [..............................] - ETA: 14:44 - loss: 1.2504 * Text to video:
 * r_1_5_10: [0.06, 0.724, 1.499]
 * medr, meanr: [257.0, 255.874]
 * ----------
 * Video to text:
 * r_1_5_10: [0.0, 0.604, 1.61]
 * medr, meanr: [620.0, 1022.05]
 * ----------
 * Current perf: 4.49698189135
 * Best perf: 6.44869215292

Epoch[10 / 50] LR: 1.13047759376e-05
----------

   120/130260 [..............................] - ETA: 14:05 - loss: 1.2497 * Text to video:
 * r_1_5_10: [0.07, 0.724, 1.559]
 * medr, meanr: [257.0, 255.996]
 * ----------
 * Video to text:
 * r_1_5_10: [0.0, 0.604, 1.408]
 * medr, meanr: [625.0, 1039.952]
 * ----------
 * Current perf: 4.3661971831
 * Best perf: 6.44869215292

Epoch[11 / 50] LR: 1.11917281782e-05
----------

   120/130260 [..............................] - ETA: 12:16 - loss: 1.2487 * Text to video:
 * r_1_5_10: [0.05, 0.724, 1.549]
 * medr, meanr: [257.0, 256.101]
 * ----------
 * Video to text:
 * r_1_5_10: [0.0, 0.402, 1.408]
 * medr, meanr: [613.0, 1056.668]
 * ----------
 * Current perf: 4.13480885312
 * Best perf: 6.44869215292

Early stopping happended.

best performance on validation: 6.44869215292

<type 'type'>
{
  "checkpoint_name": "model_best.pth.tar", 
  "workers": 5, 
  "rootpath": "../VisualSearch", 
  "batch_size": 128, 
  "log_step": 10, 
  "logger_name": "../VisualSearch/msrvtt10ktrain/cvpr_2019/msrvtt10kval/dual_encoding_concate_full_dp_0.2_measure_exp/vocab_word_vocab_5_word_dim_500_text_rnn_size_512_text_norm_True_kernel_sizes_2-3-4_num_512/visual_feature_resnet-152-img1k-flatten0_outputos_visual_rnn_size_1024_visual_norm_True_kernel_sizes_2-3-4-5_num_512/mapping_text_0-2048_img_0-2048/loss_func_cont_margin_0.2_direction_all_max_violation_True_cost_style_sum/optimizer_adam_lr_0.0001_decay_0.99_grad_clip_2.0_val_metric_recall/runs_0", 
  "testCollection": "msrvtt10ktest", 
  "n_caption": 20, 
  "overwrite": 1
}
=> loaded checkpoint '../VisualSearch/msrvtt10ktrain/cvpr_2019/msrvtt10kval/dual_encoding_concate_full_dp_0.2_measure_exp/vocab_word_vocab_5_word_dim_500_text_rnn_size_512_text_norm_True_kernel_sizes_2-3-4_num_512/visual_feature_resnet-152-img1k-flatten0_outputos_visual_rnn_size_1024_visual_norm_True_kernel_sizes_2-3-4-5_num_512/mapping_text_0-2048_img_0-2048/loss_func_cont_margin_0.2_direction_all_max_violation_True_cost_style_sum/optimizer_adam_lr_0.0001_decay_0.99_grad_clip_2.0_val_metric_recall/runs_0/model_best.pth.tar' (epoch 1, best_rsum 6.44869215292)
../VisualSearch/msrvtt10ktest/results/msrvtt10ktrain/msrvtt10kval/dual_encoding_concate_full_dp_0.2_measure_exp/vocab_word_vocab_5_word_dim_500_text_rnn_size_512_text_norm_True_kernel_sizes_2-3-4_num_512/visual_feature_resnet-152-img1k-flatten0_outputos_visual_rnn_size_1024_visual_norm_True_kernel_sizes_2-3-4-5_num_512/mapping_text_0-2048_img_0-2048/loss_func_cont_margin_0.2_direction_all_max_violation_True_cost_style_sum/optimizer_adam_lr_0.0001_decay_0.99_grad_clip_2.0_val_metric_recall/runs_0/model_best.pth.tar/pred_errors_matrix.pth.tar exists.
overwrite
[BigFile] 305462x2048 instances loaded from ../VisualSearch/msrvtt10ktest/FeatureData/resnet-152-img1k-flatten0_outputos
>>>>>>>>>>>>>>>>>>>>
Contrastive Loss Used
write into: ../VisualSearch/msrvtt10ktest/results/msrvtt10ktrain/msrvtt10kval/dual_encoding_concate_full_dp_0.2_measure_exp/vocab_word_vocab_5_word_dim_500_text_rnn_size_512_text_norm_True_kernel_sizes_2-3-4_num_512/visual_feature_resnet-152-img1k-flatten0_outputos_visual_rnn_size_1024_visual_norm_True_kernel_sizes_2-3-4-5_num_512/mapping_text_0-2048_img_0-2048/loss_func_cont_margin_0.2_direction_all_max_violation_True_cost_style_sum/optimizer_adam_lr_0.0001_decay_0.99_grad_clip_2.0_val_metric_recall/runs_0/model_best.pth.tar/pred_errors_matrix.pth.tar
 * Text to Video:
 * r_1_5_10, medr, meanr: [0.0, 0.1, 0.3, 1557.0, 1539.6]
 * recall sum: 0.5
 * mAP: 0.003
 * ----------
 * Video to text:
 * r_1_5_10, medr, meanr: [0.1, 0.1, 0.4, 2866.0, 4937.9]
 * recall sum: 0.6
 * mAP: 0.001
 * ----------
